{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGGT-based Player Localization Training\n",
    "\n",
    "This notebook trains a DETR-style decoder on top of a frozen VGGT encoder for player localization in soccer images.\n",
    "\n",
    "**Pipeline:** 1080p Image → VGGT Encoder (frozen) → DETR Decoder (trainable) → Player Positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q einops safetensors huggingface_hub scipy xtcocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repositories\n",
    "import os\n",
    "\n",
    "# Clone sskit (your fork)\n",
    "if not os.path.exists('sskit'):\n",
    "    !git clone https://github.com/hiteacherIamhumble/soccernet.git sskit\n",
    "\n",
    "# Clone VGGT\n",
    "if not os.path.exists('vggt'):\n",
    "    !git clone https://github.com/facebookresearch/vggt.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages in development mode\n",
    "!pip install -q -e sskit/\n",
    "!pip install -q -e vggt/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add paths\n",
    "import sys\n",
    "sys.path.insert(0, 'sskit')\n",
    "sys.path.insert(0, 'vggt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Data\n",
    "\n",
    "Upload your data to Google Drive or download from source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (optional - if data is stored there)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Copy data from Google Drive\n",
    "# !cp -r /content/drive/MyDrive/soccernet_data/* sskit/data/\n",
    "\n",
    "# Option 2: Download and extract data (update URLs as needed)\n",
    "# !cd sskit/data && wget <train.zip_url> && unzip -q train.zip\n",
    "# !cd sskit/data && wget <val.zip_url> && unzip -q val.zip\n",
    "# !cd sskit/data && wget <annotations.zip_url> && unzip -q annotations.zip\n",
    "\n",
    "# Verify data structure\n",
    "!ls -la sskit/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    # Data\n",
    "    data_root: str = 'sskit/data'\n",
    "    target_size: Tuple[int, int] = (1078, 1918)  # (H, W) divisible by 14\n",
    "    \n",
    "    # Model\n",
    "    hidden_dim: int = 256\n",
    "    num_queries: int = 30\n",
    "    num_decoder_layers: int = 6\n",
    "    num_heads: int = 8\n",
    "    dropout: float = 0.1\n",
    "    \n",
    "    # Training\n",
    "    epochs: int = 100\n",
    "    batch_size: int = 4\n",
    "    lr: float = 1e-4\n",
    "    weight_decay: float = 1e-4\n",
    "    warmup_epochs: int = 5\n",
    "    grad_clip: float = 0.1\n",
    "    \n",
    "    # Loss\n",
    "    weight_position: float = 5.0\n",
    "    weight_confidence: float = 1.0\n",
    "    weight_no_object: float = 0.1\n",
    "    \n",
    "    # Other\n",
    "    num_workers: int = 2\n",
    "    save_dir: str = 'checkpoints'\n",
    "    save_freq: int = 10\n",
    "    log_freq: int = 50\n",
    "    vggt_model: str = 'facebook/VGGT-1B'\n",
    "    resume: Optional[str] = None\n",
    "\n",
    "config = TrainingConfig()\n",
    "print(f\"Training config: {config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VGGT encoder (frozen)\n",
    "from vggt.models.vggt import VGGT\n",
    "\n",
    "print(f\"Loading VGGT encoder from {config.vggt_model}...\")\n",
    "encoder = VGGT.from_pretrained(config.vggt_model)\n",
    "encoder = encoder.to(device)\n",
    "encoder.eval()\n",
    "\n",
    "# Freeze all parameters\n",
    "for param in encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(\"VGGT encoder loaded and frozen.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create decoder\n",
    "from sskit.models import DETRPlayerDecoder, HungarianMatcher, SetCriterion\n",
    "\n",
    "decoder = DETRPlayerDecoder(\n",
    "    dim_in=2048,\n",
    "    hidden_dim=config.hidden_dim,\n",
    "    num_queries=config.num_queries,\n",
    "    num_decoder_layers=config.num_decoder_layers,\n",
    "    num_heads=config.num_heads,\n",
    "    dropout=config.dropout,\n",
    ").to(device)\n",
    "\n",
    "num_params = sum(p.numel() for p in decoder.parameters())\n",
    "print(f\"Decoder parameters: {num_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create loss functions\n",
    "matcher = HungarianMatcher(\n",
    "    cost_position=config.weight_position,\n",
    "    cost_confidence=config.weight_confidence,\n",
    ")\n",
    "\n",
    "criterion = SetCriterion(\n",
    "    matcher=matcher,\n",
    "    weight_position=config.weight_position,\n",
    "    weight_confidence=config.weight_confidence,\n",
    "    weight_no_object=config.weight_no_object,\n",
    ")\n",
    "\n",
    "print(\"Loss functions created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sskit.data import SynLocDataset\n",
    "from sskit.data.dataset import collate_fn\n",
    "\n",
    "data_root = Path(config.data_root)\n",
    "\n",
    "train_dataset = SynLocDataset(\n",
    "    root_dir=str(data_root / 'train'),\n",
    "    coco_json=str(data_root / 'annotations' / 'train.json'),\n",
    "    target_size=config.target_size,\n",
    ")\n",
    "\n",
    "val_dataset = SynLocDataset(\n",
    "    root_dir=str(data_root / 'val'),\n",
    "    coco_json=str(data_root / 'annotations' / 'val.json'),\n",
    "    target_size=config.target_size,\n",
    ")\n",
    "\n",
    "print(f\"Train dataset: {len(train_dataset)} images\")\n",
    "print(f\"Val dataset: {len(val_dataset)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=config.num_workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=config.num_workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Setup Optimizer and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, LinearLR, SequentialLR\n",
    "\n",
    "optimizer = AdamW(\n",
    "    decoder.parameters(),\n",
    "    lr=config.lr,\n",
    "    weight_decay=config.weight_decay,\n",
    ")\n",
    "\n",
    "warmup_scheduler = LinearLR(\n",
    "    optimizer,\n",
    "    start_factor=0.01,\n",
    "    end_factor=1.0,\n",
    "    total_iters=config.warmup_epochs,\n",
    ")\n",
    "\n",
    "main_scheduler = CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=config.epochs - config.warmup_epochs,\n",
    "    eta_min=config.lr * 0.01,\n",
    ")\n",
    "\n",
    "scheduler = SequentialLR(\n",
    "    optimizer,\n",
    "    schedulers=[warmup_scheduler, main_scheduler],\n",
    "    milestones=[config.warmup_epochs],\n",
    ")\n",
    "\n",
    "print(\"Optimizer and scheduler created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume from checkpoint (optional)\n",
    "start_epoch = 0\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "if config.resume:\n",
    "    checkpoint = torch.load(config.resume, map_location=device)\n",
    "    decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    if checkpoint['scheduler_state_dict']:\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    best_val_loss = checkpoint.get('best_val_loss', float('inf'))\n",
    "    print(f\"Resumed from epoch {start_epoch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "\n",
    "def train_one_epoch(encoder, decoder, criterion, dataloader, optimizer, device, epoch, config):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    decoder.train()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    total_loss_pos = 0.0\n",
    "    total_loss_conf = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=f'Epoch {epoch}', leave=True)\n",
    "    \n",
    "    for i, (images, targets) in enumerate(pbar):\n",
    "        # Move to device\n",
    "        images = images.to(device)\n",
    "        targets = [{k: v.to(device) if torch.is_tensor(v) else v for k, v in t.items()}\n",
    "                   for t in targets]\n",
    "        \n",
    "        # Forward through frozen encoder\n",
    "        with torch.no_grad():\n",
    "            aggregated_tokens_list, patch_start_idx = encoder.aggregator(images)\n",
    "        \n",
    "        # Forward through decoder\n",
    "        outputs = decoder(aggregated_tokens_list, patch_start_idx)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss_dict = criterion(outputs, targets)\n",
    "        loss = loss_dict['loss']\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        if config.grad_clip > 0:\n",
    "            torch.nn.utils.clip_grad_norm_(decoder.parameters(), config.grad_clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # Logging\n",
    "        total_loss += loss.item()\n",
    "        total_loss_pos += loss_dict['loss_position'].item()\n",
    "        total_loss_conf += loss_dict['loss_confidence'].item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        if (i + 1) % config.log_freq == 0 or i == len(dataloader) - 1:\n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{total_loss / num_batches:.4f}',\n",
    "                'pos': f'{total_loss_pos / num_batches:.4f}',\n",
    "                'conf': f'{total_loss_conf / num_batches:.4f}',\n",
    "            })\n",
    "    \n",
    "    return {\n",
    "        'loss': total_loss / num_batches,\n",
    "        'loss_position': total_loss_pos / num_batches,\n",
    "        'loss_confidence': total_loss_conf / num_batches,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate(encoder, decoder, criterion, dataloader, device):\n",
    "    \"\"\"Validate the model.\"\"\"\n",
    "    decoder.eval()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    total_loss_pos = 0.0\n",
    "    total_loss_conf = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc='Validation', leave=True)\n",
    "    \n",
    "    for images, targets in pbar:\n",
    "        images = images.to(device)\n",
    "        targets = [{k: v.to(device) if torch.is_tensor(v) else v for k, v in t.items()}\n",
    "                   for t in targets]\n",
    "        \n",
    "        # Forward\n",
    "        aggregated_tokens_list, patch_start_idx = encoder.aggregator(images)\n",
    "        outputs = decoder(aggregated_tokens_list, patch_start_idx)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss_dict = criterion(outputs, targets)\n",
    "        \n",
    "        total_loss += loss_dict['loss'].item()\n",
    "        total_loss_pos += loss_dict['loss_position'].item()\n",
    "        total_loss_conf += loss_dict['loss_confidence'].item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{total_loss / num_batches:.4f}',\n",
    "        })\n",
    "    \n",
    "    return {\n",
    "        'loss': total_loss / num_batches,\n",
    "        'loss_position': total_loss_pos / num_batches,\n",
    "        'loss_confidence': total_loss_conf / num_batches,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(decoder, optimizer, scheduler, epoch, config, best_val_loss, is_best=False):\n",
    "    \"\"\"Save checkpoint.\"\"\"\n",
    "    save_dir = Path(config.save_dir)\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'decoder_state_dict': decoder.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "        'best_val_loss': best_val_loss,\n",
    "        'config': vars(config) if hasattr(config, '__dict__') else config,\n",
    "    }\n",
    "    \n",
    "    # Save latest\n",
    "    torch.save(checkpoint, save_dir / 'latest.pt')\n",
    "    \n",
    "    # Save periodic\n",
    "    if (epoch + 1) % config.save_freq == 0:\n",
    "        torch.save(checkpoint, save_dir / f'epoch_{epoch+1}.pt')\n",
    "    \n",
    "    # Save best\n",
    "    if is_best:\n",
    "        torch.save(checkpoint, save_dir / 'best.pt')\n",
    "    \n",
    "    print(f\"Checkpoint saved: epoch {epoch + 1}\" + (\" (best)\" if is_best else \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create save directory\n",
    "save_dir = Path(config.save_dir)\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save config\n",
    "with open(save_dir / 'config.json', 'w') as f:\n",
    "    json.dump(vars(config) if hasattr(config, '__dict__') else config, f, indent=2)\n",
    "\n",
    "print(f\"Saving checkpoints to: {save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_loss_pos': [],\n",
    "    'train_loss_conf': [],\n",
    "    'val_loss': [],\n",
    "    'val_loss_pos': [],\n",
    "    'val_loss_conf': [],\n",
    "    'lr': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Starting training from epoch {start_epoch}...\")\n",
    "print(f\"Total epochs: {config.epochs}\")\n",
    "print(f\"Batch size: {config.batch_size}\")\n",
    "print(f\"Learning rate: {config.lr}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for epoch in range(start_epoch, config.epochs):\n",
    "    # Train\n",
    "    train_metrics = train_one_epoch(\n",
    "        encoder, decoder, criterion, train_loader, optimizer, device, epoch, config\n",
    "    )\n",
    "    \n",
    "    # Validate\n",
    "    val_metrics = validate(encoder, decoder, criterion, val_loader, device)\n",
    "    \n",
    "    # Update scheduler\n",
    "    scheduler.step()\n",
    "    current_lr = scheduler.get_last_lr()[0]\n",
    "    \n",
    "    # Log\n",
    "    print(\n",
    "        f'Epoch {epoch + 1}/{config.epochs} | '\n",
    "        f'Train: loss={train_metrics[\"loss\"]:.4f}, pos={train_metrics[\"loss_position\"]:.4f}, conf={train_metrics[\"loss_confidence\"]:.4f} | '\n",
    "        f'Val: loss={val_metrics[\"loss\"]:.4f} | '\n",
    "        f'LR: {current_lr:.6f}'\n",
    "    )\n",
    "    \n",
    "    # Update history\n",
    "    history['train_loss'].append(train_metrics['loss'])\n",
    "    history['train_loss_pos'].append(train_metrics['loss_position'])\n",
    "    history['train_loss_conf'].append(train_metrics['loss_confidence'])\n",
    "    history['val_loss'].append(val_metrics['loss'])\n",
    "    history['val_loss_pos'].append(val_metrics['loss_position'])\n",
    "    history['val_loss_conf'].append(val_metrics['loss_confidence'])\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    # Save checkpoint\n",
    "    is_best = val_metrics['loss'] < best_val_loss\n",
    "    if is_best:\n",
    "        best_val_loss = val_metrics['loss']\n",
    "    \n",
    "    save_checkpoint(decoder, optimizer, scheduler, epoch, config, best_val_loss, is_best=is_best)\n",
    "\n",
    "print(\"\\nTraining complete!\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Total loss\n",
    "ax = axes[0, 0]\n",
    "ax.plot(history['train_loss'], label='Train')\n",
    "ax.plot(history['val_loss'], label='Val')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Total Loss')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "# Position loss\n",
    "ax = axes[0, 1]\n",
    "ax.plot(history['train_loss_pos'], label='Train')\n",
    "ax.plot(history['val_loss_pos'], label='Val')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Position Loss')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "# Confidence loss\n",
    "ax = axes[1, 0]\n",
    "ax.plot(history['train_loss_conf'], label='Train')\n",
    "ax.plot(history['val_loss_conf'], label='Val')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Confidence Loss')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "# Learning rate\n",
    "ax = axes[1, 1]\n",
    "ax.plot(history['lr'])\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Learning Rate')\n",
    "ax.set_title('Learning Rate Schedule')\n",
    "ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_dir / 'training_history.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save History and Download Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save history\n",
    "with open(save_dir / 'history.json', 'w') as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "\n",
    "print(f\"Training history saved to {save_dir / 'history.json'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List saved files\n",
    "!ls -lh {config.save_dir}/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Copy to Google Drive\n",
    "# !cp -r {config.save_dir} /content/drive/MyDrive/soccernet_checkpoints/\n",
    "\n",
    "# Option 2: Download directly\n",
    "from google.colab import files\n",
    "files.download(f'{config.save_dir}/best.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Quick Inference Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint = torch.load(f'{config.save_dir}/best.pt', map_location=device)\n",
    "decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "decoder.eval()\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch'] + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on a sample\n",
    "@torch.no_grad()\n",
    "def inference_sample(encoder, decoder, dataset, idx, conf_threshold=0.5):\n",
    "    image, target = dataset[idx]\n",
    "    image = image.unsqueeze(0).to(device)  # Add batch dim\n",
    "    \n",
    "    # Forward\n",
    "    aggregated_tokens_list, patch_start_idx = encoder.aggregator(image)\n",
    "    outputs = decoder(aggregated_tokens_list, patch_start_idx)\n",
    "    \n",
    "    # Get predictions above threshold\n",
    "    positions = outputs['positions'][0]  # [N, 2]\n",
    "    confidences = outputs['confidences'][0]  # [N]\n",
    "    \n",
    "    mask = confidences > conf_threshold\n",
    "    pred_positions = positions[mask]\n",
    "    pred_scores = confidences[mask]\n",
    "    \n",
    "    return {\n",
    "        'pred_positions': pred_positions.cpu(),\n",
    "        'pred_scores': pred_scores.cpu(),\n",
    "        'gt_positions': target['positions'],\n",
    "        'num_gt': target['num_players'],\n",
    "        'image_size': target['image_size'],\n",
    "    }\n",
    "\n",
    "# Test on first validation sample\n",
    "result = inference_sample(encoder, decoder, val_dataset, 0)\n",
    "print(f\"Ground truth players: {result['num_gt']}\")\n",
    "print(f\"Predicted players (conf > 0.5): {len(result['pred_positions'])}\")\n",
    "print(f\"Confidence scores: {result['pred_scores'].tolist()[:5]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "import numpy as np\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "def visualize_predictions(dataset, idx, result):\n",
    "    image, target = dataset[idx]\n",
    "    \n",
    "    # Convert image tensor to numpy\n",
    "    img = image.squeeze(0).permute(1, 2, 0).numpy()  # [H, W, 3]\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    \n",
    "    H, W = result['image_size']\n",
    "    \n",
    "    # Denormalize positions\n",
    "    gt_pos = result['gt_positions'].numpy() * np.array([W, H])\n",
    "    pred_pos = result['pred_positions'].numpy() * np.array([W, H])\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(16, 9))\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    # Ground truth (green)\n",
    "    if len(gt_pos) > 0:\n",
    "        ax.scatter(gt_pos[:, 0], gt_pos[:, 1], c='green', s=100, marker='o', \n",
    "                   label=f'GT ({len(gt_pos)})', edgecolors='white', linewidths=2)\n",
    "    \n",
    "    # Predictions (red)\n",
    "    if len(pred_pos) > 0:\n",
    "        ax.scatter(pred_pos[:, 0], pred_pos[:, 1], c='red', s=100, marker='x',\n",
    "                   label=f'Pred ({len(pred_pos)})', linewidths=2)\n",
    "    \n",
    "    ax.legend(loc='upper right', fontsize=12)\n",
    "    ax.set_title(f'Player Localization - Image {idx}')\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_predictions(val_dataset, 0, result)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
